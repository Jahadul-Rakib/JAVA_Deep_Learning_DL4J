# Activation Function:
**Types Of Optimization Function:**
1. linear Activation Function.
2. sigmoid Activation Function.
3. tanth Activation Function.
4. ReLU Activation Function.
5. leaky ReLU (Softmax) Activation Function.

# Loss Function
**Mean Squered Error(MSE):**
When we will deal with regression. (comes output only one value).


**Negative Log Likelihood:**
When we will deal with Classification. (comes output several values)

# Optimization Function
**Gradient Descent:**
Its reduce Error as much as possible.

**Stochastic Gradient Descent:**
Its Value Update after every single training sample. Its also called mini batch Stochastic Gradient Descent.

# HyperParameters

**1. Learning Rate**
**2. Momentum**
**3. Regularization**
